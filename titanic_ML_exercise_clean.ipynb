{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning tutorial: Predicting Titanic passenger survival \n",
    "\n",
    "\n",
    "This tutorial is adapted from https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic. It was forked and modified by MSc. Benjamin Tovar (https://www.linkedin.com/in/benjamintovarcis/) on November 2015.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
    "\n",
    "Source: https://www.kaggle.com/c/titanic\n",
    "\n",
    "## Data structure and description\n",
    "\n",
    "<code>\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "</code>\n",
    "\n",
    "## Tutorial Goals\n",
    "\n",
    "The tutorial serves as an introduction to the Scikit-learn Machine Learning Python awesome library: http://scikit-learn.org/stable/index.html \n",
    "\n",
    "### Awesome tutorials and more information:\n",
    "http://www.astroml.org/sklearn_tutorial/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "# numpy\n",
    "import numpy as np\n",
    "# Machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get titanic & test csv files as a DataFrame\n",
    "titanic_df = pd.read_csv(\"data/train.csv\", dtype={\"Age\": np.float64}, )\n",
    "test_df    = pd.read_csv(\"data/test.csv\", dtype={\"Age\": np.float64}, )\n",
    "\n",
    "# preview the data\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop unnecessary columns, these columns won't be useful in analysis and prediction\n",
    "titanic_df = titanic_df.drop(['PassengerId','Name','Ticket'], axis=1)\n",
    "test_df    = test_df.drop(['Name','Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing a meta-feature (artificial feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sex\n",
    "\n",
    "# As already known, children(age < ~16) on aboard seem to have a high chances for Survival.\n",
    "# So, we can classify passengers as males, females, and child\n",
    "def get_person(passenger):\n",
    "    age,sex = passenger\n",
    "    return 'child' if age < 16 else sex\n",
    "    \n",
    "titanic_df['Person'] = titanic_df[['Age','Sex']].apply(get_person,axis=1)\n",
    "test_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n",
    "\n",
    "# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers\n",
    "person_dummies_titanic  = pd.get_dummies(titanic_df['Person'])\n",
    "person_dummies_titanic.columns = ['Male','Female','Child']\n",
    "# person_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "person_dummies_test  = pd.get_dummies(test_df['Person'])\n",
    "person_dummies_test.columns = ['Male','Female','Child']\n",
    "# person_dummies_test.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "titanic_df = titanic_df.join(person_dummies_titanic)\n",
    "test_df    = test_df.join(person_dummies_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring likelihood of survival given gender and age -> `Person` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the number of persons for each category (child, adult female or adult male)\n",
    "family_survived = titanic_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False)\n",
    "family_survived.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the number of persons that survived given each category\n",
    "family_survived.Survived.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count the proportion in % of persons that survived vs count for each category\n",
    "family_survived_perc = family_survived.Survived.sum().Survived / family_survived.Survived.count().Survived * 100\n",
    "family_survived_perc_df = pd.DataFrame(family_survived_perc)\n",
    "family_survived_perc_df.columns = [\"Survived %\"]\n",
    "family_survived_perc_df.index = [\"Child\",\"Female\",\"Male\"]\n",
    "family_survived_perc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Perform the same analysis for Class of passenger: `Pclass` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the total count of persons belonging to each class\n",
    "pclass_survived = \"<FILL CODE HERE>\"\n",
    "pclass_survived.count()\n",
    "# OUTPUT MUST BE:\n",
    "#  Pclass Survived\n",
    "#  1       216\n",
    "#  2       184\n",
    "#  3       491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the count of persons that survived belonging to each class \n",
    "\"<FILL CODE HERE>\"\n",
    "# OUTPUT MUST BE:\n",
    "#  Pclass Survived\n",
    "#  1       136\n",
    "#  2       87\n",
    "#  3       119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the % of persons that survived versus the total for each class\n",
    "pclass_survived_perc = \"<FILL CODE HERE>\"\n",
    "pclass_survived_perc_df = pd.DataFrame(pclass_survived_perc)\n",
    "pclass_survived_perc_df.columns = [\"Survived %\"]\n",
    "pclass_survived_perc_df.index = [\"1st\",\"2nd\",\"3rd\"]\n",
    "pclass_survived_perc_df\n",
    "# OUTPUT MUST BE IN THE FOLLOWING FORMAT:\n",
    "#       Survived %\n",
    "#  1st  12.345678\n",
    "#  2nd  12.345678\n",
    "#  3rd  12.345678"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate answer!\n",
    "x = pclass_survived_perc_df[2:3]\n",
    "if round(x.sum()) == 24.0:\n",
    "    print \"Success!, Task 1 completed and one step closer to chilaquiles\"\n",
    "else:\n",
    "    print \"Sorry, try again or there won't be chilaquiles for ya!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the classifier (Preparing data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set features to drop\n",
    "features_to_drop = [\"Person\",\"Sex\",\"Cabin\",\"Embarked\"]\n",
    "# drop features for train and test\n",
    "titanic_df.drop(features_to_drop,axis=1,inplace=True)\n",
    "test_df.drop(features_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explore train set\n",
    "titanic_df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train set (droping rows with NULL values)\n",
    "X_train = titanic_df.dropna()\n",
    "# set train set labels (event of survival: 1, event of no-survival: 0)\n",
    "Y_train = X_train[\"Survived\"]\n",
    "# drop labels from training set, given that label is the dependant feature\n",
    "# and we want to predict label given predictors or independent features\n",
    "X_train = X_train.drop(\"Survived\",axis=1)\n",
    "\n",
    "# Test set (droping rows with NULL values)\n",
    "# make a copy of PassengerId\n",
    "X_test  = test_df.drop(\"PassengerId\",axis=1).dropna().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the classifier (Machine Learing models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a classifier object initialized with our parameters\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "# fit labels to predictors (in other words, use predictors to infer label)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "# Make predictions on predictors from test set\n",
    "# a prediction has a value of 1 when the model predicts that a person will survive\n",
    "# and 0 otherwise\n",
    "Y_pred_rf = random_forest.predict(X_test)\n",
    "# compute the performance of the learning algorithm\n",
    "random_forest.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors Classification\n",
    "\n",
    "http://scikit-learn.org/stable/modules/neighbors.html\n",
    "\n",
    "Neighbors-based classification is a type of instance-based learning or non-generalizing learning: it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.\n",
    "\n",
    "scikit-learn implements two different nearest neighbors classifiers: KNeighborsClassifier implements learning based on the k nearest neighbors of each query point, where k is an integer value specified by the user. RadiusNeighborsClassifier implements learning based on the number of neighbors within a fixed radius r of each training point, where r is a floating-point value specified by the user.\n",
    "\n",
    "The k-neighbors classification in KNeighborsClassifier is the more commonly used of the two techniques. The optimal choice of the value k is highly data-dependent: in general a larger k suppresses the effects of noise, but makes the classification boundaries less distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a classifier object initialized with our parameters\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "# fit labels to predictors (in other words, use predictors to infer label)\n",
    "knn.fit(\"<FILL CODE HERE>\")\n",
    "# Make predictions on predictors from test set\n",
    "# a prediction has a value of 1 when the model predicts that a person will survive\n",
    "# and 0 otherwise\n",
    "Y_pred_knn = \"<FILL CODE HERE>\"\n",
    "# compute the performance of the learning algorithm\n",
    "knn.score(\"<FILL CODE HERE>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n",
    "http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "The advantages of support vector machines are:\n",
    "\n",
    "- Effective in high dimensional spaces.\n",
    "- Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "- Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "- Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "\n",
    "- If the number of features is much greater than the number of samples, the method is likely to give poor performances.\n",
    "- SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a classifier object initialized with our parameters\n",
    "# SVC -> Support Vector Classification\n",
    "svc = SVC()\n",
    "# fit labels to predictors (in other words, use predictors to infer label)\n",
    "svc.fit(\"<FILL CODE HERE>\")\n",
    "# Make predictions on predictors from test set\n",
    "# a prediction has a value of 1 when the model predicts that a person will survive\n",
    "# and 0 otherwise\n",
    "Y_pred_svc = \"<FILL CODE HERE>\"\n",
    "# compute the performance of the learning algorithm\n",
    "svc.score(\"<FILL CODE HERE>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Benchmark score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# benchmark score is the \"agreement\" score between the 3 models\n",
    "benchmark_score = (Y_pred_rf + Y_pred_knn + Y_pred_svc) / float(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct data frame\n",
    "submission = pd.DataFrame({\n",
    "        \"1_PassengerId\": test_df.dropna().PassengerId,\n",
    "        \"2_Survived_(RandomForest)\": Y_pred_rf,\n",
    "        \"3_Survived_(KNN)\": Y_pred_knn,\n",
    "        \"4_Survived_(SVM)\": Y_pred_svc,\n",
    "        \"5_Benchmark_score\": benchmark_score\n",
    "        \n",
    "    })\n",
    "# export to CSV\n",
    "submission.to_csv('titanic_prediction_benchmark.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show output in notebook\n",
    "submission.head(n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
